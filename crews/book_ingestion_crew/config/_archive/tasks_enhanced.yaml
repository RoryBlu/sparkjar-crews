# Enhanced Book Ingestion Tasks Configuration
# IMPORTANT: All image viewing MUST use ImageViewerTool - agents cannot view images directly

list_book_files:
  description: |
    List all image files in the Google Drive folder: {google_drive_folder_path}
    
    IMPORTANT: Files use batch-based naming with 25 pages per batch.
    Example: "batch_100_page_0.jpg" through "batch_100_page_24.jpg" represents pages 100-124.
    
    To calculate the actual page number:
    - Extract batch number (e.g., 100 from "batch_100_page_0.jpg")
    - Extract position in batch (e.g., 0 from "batch_100_page_0.jpg")
    - Page number = batch_start + position_in_batch
    - So "batch_100_page_0.jpg" = page 100, "batch_100_page_24.jpg" = page 124
    
    Sort files by calculated page number (not alphabetically).
    Return a structured list with file IDs, names, and calculated page numbers.
  expected_output: |
    A JSON array of files with:
    - file_id: Google Drive file ID
    - file_name: Original filename
    - calculated_page_number: Actual page number (batch + position)
    - mime_type: Image MIME type
    Example:
    [
      {"file_id": "abc123", "file_name": "batch_100_page_0.jpg", "calculated_page_number": 100, "mime_type": "image/jpeg"},
      {"file_id": "def456", "file_name": "batch_100_page_1.jpg", "calculated_page_number": 101, "mime_type": "image/jpeg"}
    ]
  agent: file_manager

ocr_initial_pass:
  description: |
    Perform initial OCR on page {page_number} using the ImageViewerTool.
    
    Download the file from Google Drive first, then use the image_viewer tool with this EXACT prompt:
    
    "You are transcribing a {language} manuscript page {page_number}.
    
    Book Context:
    - Title: {book_title}
    - Author: {book_author}
    - Description: {book_description}
    - Year: {book_year}
    
    This helps you correctly interpret:
    - Dates and time periods mentioned in the text
    - Place names and locations
    - Character names and relationships
    - Cultural or historical references
    
    Instructions:
    1. Transcribe EXACTLY what you see on the page
    2. Use the book context to correctly interpret ambiguous text
    3. For unclear text:
       - Mark with [?] if you can partially read it
       - Mark as [illegible] if completely unreadable
       - Note WHY it's unclear (faded, smudged, torn, etc.)
    4. Track confidence levels:
       - HIGH: Clear, unambiguous text (>90% certain)
       - MEDIUM: Readable with some effort (70-90% certain)
       - LOW: Significant uncertainty (<70% certain)
    
    Return a JSON response with this structure:
    {
      'transcription': 'The complete text of the page',
      'unclear_sections': [
        {
          'text': 'the unclear [?] portion',
          'position': 'line 5, words 3-4',
          'confidence': 'LOW',
          'reason': 'faded ink',
          'context': 'surrounded by: before text ... after text'
        }
      ],
      'overall_confidence': 0.85,
      'metadata': {
        'line_count': 25,
        'word_count': 250,
        'language_detected': '{language}',
        'handwriting_style': 'cursive/print/mixed',
        'ink_quality': 'good/faded/variable',
        'page_condition': 'excellent/good/damaged'
      }
    }"
    
    Remember: You are using the image_viewer tool - you cannot see the image directly.
    The tool will return the JSON response from GPT-4o's analysis.
  expected_output: |
    JSON containing:
    - transcription: Complete page text with [?] markers
    - unclear_sections: Detailed list of uncertainties
    - overall_confidence: Score between 0.0 and 1.0
    - metadata: OCR process details
  agent: vision_specialist
  context: [list_book_files]

ocr_refinement_pass:
  description: |
    Refine the OCR results for page {page_number} using ImageViewerTool with enhanced context.
    
    Only execute this task if overall_confidence from initial pass is below {confidence_threshold}.
    
    Use the image_viewer tool with this enhanced prompt:
    
    "Please review and improve this transcription of manuscript page {page_number}.
    
    Previous transcription:
    {initial_transcription}
    
    Specific unclear sections to focus on:
    {unclear_sections}
    
    Additional context:
    - Previous page ended with: '{previous_page_context}'
    - This helps understand story flow and incomplete sentences
    
    For each unclear section:
    1. Look at the specific area mentioned
    2. Consider the narrative context
    3. Analyze letter shapes and patterns
    4. Think about common {language} words that fit
    5. Consider the handwriting style consistency
    
    Improvement strategies:
    - If a word starts at the end of the previous page, complete it
    - Use story context to deduce character names or places
    - Look for repeated words elsewhere on the page for comparison
    - Consider common phrases in {language} literature
    
    Return updated JSON with your improvements and reasoning."
    
    The image_viewer tool will analyze the image again with this context.
  expected_output: |
    Refined JSON with:
    - transcription: Improved text
    - unclear_sections: Remaining uncertainties (should be fewer)
    - overall_confidence: Updated score (should be higher)
    - changes_made: List of specific improvements
    - reasoning: Explanation for each change
  agent: vision_specialist
  context: [ocr_initial_pass]

ocr_reasoning_pass:
  description: |
    Use sequential thinking AND ImageViewerTool to resolve remaining uncertainties.
    
    Only execute if unclear sections remain after refinement pass.
    
    First, create a thinking session to analyze the problem:
    1. What patterns do we see in the unclear text?
    2. What context clues are available?
    3. What specific questions should we ask about each unclear section?
    
    Then, for EACH unclear section, use the image_viewer tool with targeted prompts like:
    
    "Focus on this specific text area: '{unclear_text}' at position {position}
    
    Context from our analysis:
    - This appears to be a {word_type} (name/place/action/etc)
    - Previous context: '{previous_context}'
    - Following context: '{following_context}'
    - The handwriting pattern suggests: {pattern_observation}
    
    Specific questions:
    1. Does the first letter look more like {option1} or {option2}?
    2. How many letters are in this word?
    3. Are there any distinguishing features (dots, accents, curves)?
    4. Does this match any common {language} words of similar length?
    
    Based on careful examination, what is the most likely text?"
    
    Combine the thinking session insights with targeted ImageViewerTool analysis.
  expected_output: |
    Final JSON with:
    - transcription: Final text with all deductions made
    - confidence: Final confidence score (aim for >0.95)
    - thinking_session_id: ID of the thinking session used
    - deductions_made: List of reasoned corrections with explanations
    - remaining_uncertainties: Any text still unclear (should be minimal)
  agent: reasoning_specialist
  context: [ocr_refinement_pass]

store_page_to_database:
  description: |
    Store the transcribed page {page_number} to the database using the database_storage tool.
    
    Prepare the data for storage:
    - book_key: Extract from '{google_drive_folder_path}' (last folder name)
    - page_number: {page_number}
    - file_name: {file_name}
    - page_text: Final transcription from OCR process
    - language_code: {language}
    - version: 'original' (default)
    - ocr_metadata: Include all OCR process data:
      * initial_confidence
      * final_confidence
      * passes_used (1, 2, or 3)
      * unclear_sections_resolved
      * reasoning_used (true/false)
      * processing_time
      * handwriting_style
      * page_condition
    
    The database_storage tool will:
    1. Store the page in book_ingestions table
    2. Generate overlapping text chunks (512 chars with 128 overlap)
    3. Create embeddings for each chunk
    4. Store embeddings in object_embeddings table
    
    Ensure all data is properly formatted before calling the tool.
  expected_output: |
    Storage confirmation with:
    - page_id: UUID of the stored page
    - embedding_count: Number of embeddings created
    - success: true/false
    - error: Any error message (null if successful)
    Example:
    {
      "page_id": "123e4567-e89b-12d3-a456-426614174000",
      "embedding_count": 5,
      "success": true,
      "error": null
    }
  agent: data_specialist
  context: [ocr_initial_pass, ocr_refinement_pass, ocr_reasoning_pass]

compile_book_results:
  description: |
    Compile the final results for the entire book processing job.
    
    Analyze all processed pages and create a comprehensive summary:
    
    1. Statistics:
       - Total pages found in Google Drive
       - Pages successfully processed
       - Pages that failed (with reasons)
       - Average confidence scores (initial vs final)
       - Distribution of passes used (how many needed 1, 2, or 3 passes)
    
    2. Quality Analysis:
       - Most common types of uncertainties
       - Pages with lowest confidence (may need manual review)
       - Handwriting quality patterns
       - Language consistency
    
    3. Performance Metrics:
       - Total processing time
       - Average time per page
       - Time spent on each pass type
       - Database storage success rate
    
    4. Recommendations:
       - Pages that may need manual review
       - Suggestions for improving future runs
       - Patterns identified that could help with similar books
    
    Create a clear, actionable report for the client.
  expected_output: |
    Comprehensive report with:
    - book_key: Identifier for this book
    - total_pages: Number of pages in Google Drive
    - completed_pages: Successfully processed and stored
    - failed_pages: List with page numbers and error reasons
    - average_initial_confidence: Before refinement
    - average_final_confidence: After all passes
    - processing_time_minutes: Total time for the job
    - pass_distribution: {"1_pass": 10, "2_pass": 5, "3_pass": 2}
    - recommendations: List of actionable suggestions
    - pages_for_review: List of pages with confidence < 0.90
  agent: project_manager
  context: [store_page_to_database]